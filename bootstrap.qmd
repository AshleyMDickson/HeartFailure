---
title: "Bootstrapping & Sample Sizes"
---

On the previous page, we ran through some manual bootstrapping for the purposes of showing their in-principle operation. There we used just a single predictor and a relatively small sample size.

Now let's try to develop a bigger bootstrap validation procedure with a bigger sample size and more covariates. Again, start by generating some sample data, this time with $\beta_0=-1.5$ and predictor effects $\beta_k = 0.7$ for $1 \leq k \leq 10$.

```{r}
set.seed(11235)
k <- 10
n <- 100000
beta_0 <- -1.5
beta <- rep(0.7, k)

simulate_data <- function(k, n) {
  X <- matrix(rnorm(n*k), nrow = n, ncol = k)
  colnames(X) <- paste0("x", 1:k)
  eta <- beta_0 + X %*% beta
  p <- 1 / (1 + exp(-eta))
  y <- rbinom(n, size = 1, prob = p)
  return(
    list(
      df = data.frame(X, y = y),
      eta = eta,
      p = p
    )
  )
}

dgp_data <- simulate_data(k, n)
df <- dgp_data$df
print(paste0("Hence a prevalence of ", round(100 * mean(df$y), 2), "%"))
```

Visualise:

```{r}
hist(df$eta, breaks = 100, col = "lightblue", main = "Distribution of Linear Predictor",
     xlab = expression(eta))#, freq = FALSE)
```

```{r}
hist(df$p, breaks = 100, main = "Distribution of Probabilities",
     xlab = "Theoretical Probability")#, freq = FALSE)
```
```{r}
library(ggplot2)
ggplot(df, aes(x = eta, y = p)) +
  geom_line(stat = "function", fun = plogis, linewidth = 1) +
  labs(x = "Linear Predictor (η)", y = "Probability (p)", title = "Logistic Function: p = 1 / (1 + exp(-η))") +
  theme_minimal()
```

## Create dataframe and model

```{r}
library(rms)
df <- as.data.frame(X)
df$y <- y
dd <- datadist(df)
options(datadist = "dd")
fit <- lrm(y ~ ., data = df, x=TRUE,y=TRUE)
print(fit)
```

```{r}
summary(fit)
```

To do: what is an effect in this context? Why are these ORs different from $\exp(\beta)$

```{r}
exp(fit$coefficients)
```

## Initial Model Validation

```{r}
val <- validate(fit, method = "boot", B = 200)
val
```
```{r}
auc <- (val["Dxy", "index.corrected"] + 1) / 2
print(auc)
```

## Sample Size

I would like to understand the effect of sample size on model performance. Here I focus on two methods of model validation -- Cross Validation (10-fold) and Bootstrapping -- and applying them to the model formulation given above on variable sample sizes.

Let's start by setting up the basics:

```{r}
df <- dgp_data$df

sample_sizes <- c(100, 200, 300, 500, 1000)
B <- 200
performance_metrics <- c('AUC', 'calibration_slope')
```

So we have a vector of sample sizes, a number of bootstrap repetitions, and we would like to use 2 performance metrics (AUC, Calibration slope) for understand the impact of sample size on model performance.

Hence we need to calculate 5 * 200 * 2 = 2000 data points, stored in a 4D data structure.

Next let's set up a nested-list data structure to hold the results.

```{r}
results <- list()
for (s in sample_sizes) {
  results[[as.character(s)]] <- list(auc = numeric(B), slope = numeric(B))
}
#results
```

Each of these datapoints will be populated with either an AUC value or a calibration slope. Let's start with a simple function that will allow us to calculate a single result. Later we will wrap this inside a double-loop to populate the results list.

```{r}
performance <- function() {
  
}
```



Now loop through the list of sample size, and for each sample size, take a development sample of that size.
Then draw B bootstrap samples and run the model on each, reporting AUC and calibration-slope from both


```{r}
library(pROC)
library(tidyverse)

for (s in sample_sizes) {
  dev_sample <- sample_n(df, s, replace = FALSE)
  
  for (b in 1:B) {
    boot_sample <- sample(dev_sample, s, replace = TRUE)
    mod <- glm(y ~ ., family = "binomial", data = boot_sample)
   # Make sure the prediction only uses the variables that were in the fitted model
    pred_vars <- names(coef(mod))[-1]  # remove intercept
    X_pred <- dev_sample[, pred_vars, drop = FALSE]

    # Ensure X_pred has all the necessary variables, even if constant
    for (var in pred_vars) {
      if (!(var %in% names(X_pred))) {
        X_pred[[var]] <- 0  # or any constant value
  }
}

pred_dev_p <- predict(mod, newdata = X_pred, type = "response")
pred_dev_l <- predict(mod, newdata = X_pred, type = "link")
    
    auc <- roc(dev_sample$y, pred_dev_p, quiet = TRUE)$auc
    #cal_mod <- glm(dev_sample$y ~ pred_dev_l, family = "binomial")
    #slope <- coef(cal_mod)[2]
    
    results[[as.character(s)]] [["bootstrap"]] [["auc"]] [b] <- auc
    #results[[as.character(s)]] [["bootstrap"]] [["slope"]] [b] <- slope
  }
}
```

